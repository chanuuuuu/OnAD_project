{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from komoran3py import KomoranPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = KomoranPy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./df_1.pickle', 'rb') as f : \n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>배경음 love theme의 감동적인 선율과 영사기에서 나오는 달콤한 키스 장면들을...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>불멸의 명작. 영화인을 꿈꾸는 사람이라면 반드시 봐야할 영화</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>탄탄한 스토리와 거장 엔니오 모리꼬네가 만들어낸 최고의 영화. 몇번을 봐도 마지막장...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>20년이 훨씬 지났지만 아직도 생각하면 가슴이 벅차네요...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>오랜만에 다시 보아도 너무 예쁘고 사랑스런 눈물나게 하는 영화</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>지금 극장에 걸려 있는 건 축약판(123분). 축약판만 보신 분들은 꼭 감독판(17...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>아 근데 재개봉 버전 뭐이렇게 삭제된 장면이 많냐;; 후반 엘레나 시퀀스는 통째로 ...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>영화관에서 절대 보지말아라 이야기를 끌어가는 주요 이야기인 엘레나와 토토의 재회부분...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>삶의 모든 것이 들어있었다 ㅠㅠ</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10대에 보았다 그때는 왜 눈물이 그치지 않는지 알수가 없었다. 30중반 이제서 다...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>신촌cgv에서 예전시네마천국  기대했는데   너무영화가  뚝뚝 끊어지냉 ㄴ누가  편...</td>\n",
       "      <td>NEUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>살바토레와 알프레도의 케미는 가히 역대급이다... 명작의 가치는 역시 시대를 초월한다</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>아주  먼  훗날, 이제  더는  흘릴  눈물이 남아 있을 것 같지  않을 그 날에...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>무슨 네오리얼리즘 영화도 아니고 구지 해석하고 분석하려 하지 말아라.그냥 그대로 보...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>ost만 들어도 눈물나는 영화</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>왜 죽기 전에 꼭 봐야 하는 영화인지 알겠습니다. 오늘 12시 15분에 관람했는데 ...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>마지막 장면은 절대 잊을 수 없을 것이다!</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>살아가는 동안 누구나 하나쯤 시네마천국을 가질것이다. 이영화는 나의 시네마천국을 생...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>제 인생 최고의 영화였습니다.아직도 이보다 더한 감동과그리움을 느끼는 영화는 만나지...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>너무슬프다.. 말그대로 명작이다</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>방금 감독판 봤는데 이런 걸작을 지금까지 못본게 후회가 될만큼 큰 감명을 받았네요....</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>최고의 영화를 지금 다시 볼 수 있어서 좋았습니다.</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>1990년 고1때 영화관에서 돈주고 2번 본영화~친척언니랑 여름방학때보고 넘감동적인...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>시대는 변하고 기억은 변하지 않기때문에아름답게 추억할수있는 과거</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>마지막 장면은 울지 않고는 볼 수 없었다는...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>영화는 무엇일까? 인생의 또다른 말이 아닐까?</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>단언컨대, 시네마 천국은 최고의 영화입니다</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>이 영화에 10점 못 주는 사람은 가슴 어딘가에 이상이 있지 않을까?</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>어떠한 긴 말보다 엄청난 감동이 밀려오는 영화입니다.</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>역시 엔리오모리꼬네 영화음악은 말할것없고. 영화에 대한순수한마음이느껴져 좋았다 일상...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>1</td>\n",
       "      <td>홍성빈같은 영화 한마디로 별로</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>1</td>\n",
       "      <td>재밌지만 너무높은듯..</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>1</td>\n",
       "      <td>솔직히 길고 지루하다.</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>1</td>\n",
       "      <td>평점이해안감;;;;;;;</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>1</td>\n",
       "      <td>너무 진부하고 너무 지루하다 난 또 대단한 영화인 줄 알고 봤더니 그냥 뻔한 멜로물</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>1</td>\n",
       "      <td>남들이 10점줄때 1점 줄 수 있는 용기도 필요하다!</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>1</td>\n",
       "      <td>ㅂㅅ들이냐 이탈리아사람들한테만 특별한의미가 있어 평점이높은건데 우리나라사남이 보고 ...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>1</td>\n",
       "      <td>졸작</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>1</td>\n",
       "      <td>비추</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>1</td>\n",
       "      <td>이거 포르노임? 주인공 변태,불륜 스토커네 OO..내생에 최악의 영화!!!</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>1</td>\n",
       "      <td>알프레도... 알고 보면 나쁜 놈이다. 솔직히 토토가 엘레나와 헤어지게 된 것은 엘...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>1</td>\n",
       "      <td>성매매,스토킹,불륜... 이런 쓰레기 영화가 어떻게 전체관람가냐?</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>2</td>\n",
       "      <td>개노잼인데????왜그렇게 극찬하는거야대체?</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>1</td>\n",
       "      <td>평점 1위라 봣는데 개 별로ㅡㅡ</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>1</td>\n",
       "      <td>평점 높아서 기대하고 봤는데 정말 실망이 크네요</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>1</td>\n",
       "      <td>평점깎깅ㅍㅅㄴㅋ다라</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>1</td>\n",
       "      <td>몇번이나 시도했지만 매번 끝까지 완주하지 못했다</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>1</td>\n",
       "      <td>워낙 이름난 작품이라 봤는데, 저는 왠지 별 감흥이 없네요. 나중에 다시 한번 볼께요.</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>1</td>\n",
       "      <td>아아아아오아아아오어어어</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>1</td>\n",
       "      <td>너무 좋은 영화인거 같다. 한번 더 볼 생각이 있음</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>1</td>\n",
       "      <td>뭐야이건완전옛날영화왜다시개봉하는지</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>1</td>\n",
       "      <td>제밌나요? 이런우연가능한가요?</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>1</td>\n",
       "      <td>음.. 뭔가 기대이하야</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>1</td>\n",
       "      <td>고마 내리자 마 할만큼햇다 아니가</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>1</td>\n",
       "      <td>아 정말 다좋은데 왜 하필 중년의 살바토레가 전혀매치안되는 인물로 나온거야....</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>1</td>\n",
       "      <td>최악의영화인것같았다.</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>1</td>\n",
       "      <td>과대 평가된 영화라고 생각됨....</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>1</td>\n",
       "      <td>왠지영화랑인물이매치가안된다.</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>1</td>\n",
       "      <td>언제적영화냐 그만하자ㅋㅋ모야이건</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>1</td>\n",
       "      <td>평점 너무 높음;;</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3465 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating                                             review   emo\n",
       "0         10  배경음 love theme의 감동적인 선율과 영사기에서 나오는 달콤한 키스 장면들을...   POS\n",
       "1          9                  불멸의 명작. 영화인을 꿈꾸는 사람이라면 반드시 봐야할 영화   POS\n",
       "2         10  탄탄한 스토리와 거장 엔니오 모리꼬네가 만들어낸 최고의 영화. 몇번을 봐도 마지막장...   POS\n",
       "3         10                  20년이 훨씬 지났지만 아직도 생각하면 가슴이 벅차네요...   POS\n",
       "4         10                 오랜만에 다시 보아도 너무 예쁘고 사랑스런 눈물나게 하는 영화   POS\n",
       "5         10  지금 극장에 걸려 있는 건 축약판(123분). 축약판만 보신 분들은 꼭 감독판(17...   POS\n",
       "6         10  아 근데 재개봉 버전 뭐이렇게 삭제된 장면이 많냐;; 후반 엘레나 시퀀스는 통째로 ...   POS\n",
       "7          1  영화관에서 절대 보지말아라 이야기를 끌어가는 주요 이야기인 엘레나와 토토의 재회부분...   NEG\n",
       "8         10                                  삶의 모든 것이 들어있었다 ㅠㅠ   POS\n",
       "9         10  10대에 보았다 그때는 왜 눈물이 그치지 않는지 알수가 없었다. 30중반 이제서 다...   POS\n",
       "10         6  신촌cgv에서 예전시네마천국  기대했는데   너무영화가  뚝뚝 끊어지냉 ㄴ누가  편...  NEUT\n",
       "11         9    살바토레와 알프레도의 케미는 가히 역대급이다... 명작의 가치는 역시 시대를 초월한다   POS\n",
       "12        10  아주  먼  훗날, 이제  더는  흘릴  눈물이 남아 있을 것 같지  않을 그 날에...   POS\n",
       "13        10  무슨 네오리얼리즘 영화도 아니고 구지 해석하고 분석하려 하지 말아라.그냥 그대로 보...   POS\n",
       "14        10                                   ost만 들어도 눈물나는 영화   POS\n",
       "15        10  왜 죽기 전에 꼭 봐야 하는 영화인지 알겠습니다. 오늘 12시 15분에 관람했는데 ...   POS\n",
       "16        10                            마지막 장면은 절대 잊을 수 없을 것이다!   POS\n",
       "17        10  살아가는 동안 누구나 하나쯤 시네마천국을 가질것이다. 이영화는 나의 시네마천국을 생...   POS\n",
       "18        10  제 인생 최고의 영화였습니다.아직도 이보다 더한 감동과그리움을 느끼는 영화는 만나지...   POS\n",
       "19        10                                  너무슬프다.. 말그대로 명작이다   POS\n",
       "20        10  방금 감독판 봤는데 이런 걸작을 지금까지 못본게 후회가 될만큼 큰 감명을 받았네요....   POS\n",
       "21         9                       최고의 영화를 지금 다시 볼 수 있어서 좋았습니다.   POS\n",
       "22        10  1990년 고1때 영화관에서 돈주고 2번 본영화~친척언니랑 여름방학때보고 넘감동적인...   POS\n",
       "23         8                시대는 변하고 기억은 변하지 않기때문에아름답게 추억할수있는 과거   POS\n",
       "24        10                         마지막 장면은 울지 않고는 볼 수 없었다는...   POS\n",
       "25         8                          영화는 무엇일까? 인생의 또다른 말이 아닐까?   POS\n",
       "26        10                            단언컨대, 시네마 천국은 최고의 영화입니다   POS\n",
       "27        10             이 영화에 10점 못 주는 사람은 가슴 어딘가에 이상이 있지 않을까?   POS\n",
       "28        10                      어떠한 긴 말보다 엄청난 감동이 밀려오는 영화입니다.   POS\n",
       "29         9  역시 엔리오모리꼬네 영화음악은 말할것없고. 영화에 대한순수한마음이느껴져 좋았다 일상...   POS\n",
       "...      ...                                                ...   ...\n",
       "3435       1                                   홍성빈같은 영화 한마디로 별로   NEG\n",
       "3436       1                                       재밌지만 너무높은듯..   NEG\n",
       "3437       1                                       솔직히 길고 지루하다.   NEG\n",
       "3438       1                                      평점이해안감;;;;;;;   NEG\n",
       "3439       1     너무 진부하고 너무 지루하다 난 또 대단한 영화인 줄 알고 봤더니 그냥 뻔한 멜로물   NEG\n",
       "3440       1                      남들이 10점줄때 1점 줄 수 있는 용기도 필요하다!   NEG\n",
       "3441       1  ㅂㅅ들이냐 이탈리아사람들한테만 특별한의미가 있어 평점이높은건데 우리나라사남이 보고 ...   NEG\n",
       "3442       1                                                 졸작   NEG\n",
       "3443       1                                                 비추   NEG\n",
       "3444       1          이거 포르노임? 주인공 변태,불륜 스토커네 OO..내생에 최악의 영화!!!   NEG\n",
       "3445       1  알프레도... 알고 보면 나쁜 놈이다. 솔직히 토토가 엘레나와 헤어지게 된 것은 엘...   NEG\n",
       "3446       1               성매매,스토킹,불륜... 이런 쓰레기 영화가 어떻게 전체관람가냐?   NEG\n",
       "3447       2                            개노잼인데????왜그렇게 극찬하는거야대체?   NEG\n",
       "3448       1                                  평점 1위라 봣는데 개 별로ㅡㅡ   NEG\n",
       "3449       1                         평점 높아서 기대하고 봤는데 정말 실망이 크네요   NEG\n",
       "3450       1                                         평점깎깅ㅍㅅㄴㅋ다라   NEG\n",
       "3451       1                         몇번이나 시도했지만 매번 끝까지 완주하지 못했다   NEG\n",
       "3452       1   워낙 이름난 작품이라 봤는데, 저는 왠지 별 감흥이 없네요. 나중에 다시 한번 볼께요.   NEG\n",
       "3453       1                                       아아아아오아아아오어어어   NEG\n",
       "3454       1                       너무 좋은 영화인거 같다. 한번 더 볼 생각이 있음   NEG\n",
       "3455       1                                 뭐야이건완전옛날영화왜다시개봉하는지   NEG\n",
       "3456       1                                   제밌나요? 이런우연가능한가요?   NEG\n",
       "3457       1                                       음.. 뭔가 기대이하야   NEG\n",
       "3458       1                                 고마 내리자 마 할만큼햇다 아니가   NEG\n",
       "3459       1      아 정말 다좋은데 왜 하필 중년의 살바토레가 전혀매치안되는 인물로 나온거야....   NEG\n",
       "3460       1                                        최악의영화인것같았다.   NEG\n",
       "3461       1                                과대 평가된 영화라고 생각됨....   NEG\n",
       "3462       1                                    왠지영화랑인물이매치가안된다.   NEG\n",
       "3463       1                                  언제적영화냐 그만하자ㅋㅋ모야이건   NEG\n",
       "3464       1                                         평점 너무 높음;;   NEG\n",
       "\n",
       "[3465 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(x) : \n",
    "    if x == 'POS' : \n",
    "        x = 1\n",
    "        return x\n",
    "    elif x == 'NEUT' : \n",
    "        x = 0\n",
    "        return x\n",
    "    else : \n",
    "        x = -1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emo'] = df['emo'].apply(lambda x : label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_komoran(x) : \n",
    "    tmp_list = []\n",
    "    tmp = ko.pos(x)\n",
    "    for i in range(len(tmp)) : \n",
    "        tmp_list.append(tmp[i][0])\n",
    "    return tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['review'].apply(lambda x : tokenizer_komoran(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( df['review'], df['emo']\n",
    "                                                                  ,test_size=0.3, random_state=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['y_test'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>y_test</th>\n",
       "      <th>X_test_tokkend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>세월이 흘러도 잊혀지지 않는 생생한 OST의 전율</td>\n",
       "      <td>0</td>\n",
       "      <td>[세월, 이, 흐르, 어도, 잊히, 어, 지, 지, 않, 는, 생생, 하, ㄴ, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>언제든 다시 봐도 명작.,.</td>\n",
       "      <td>1</td>\n",
       "      <td>[언제, 이, 든, 다시, 보, 아도, 명작, ., ,, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>최고</td>\n",
       "      <td>1</td>\n",
       "      <td>[최고]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>나의 질풍노도 시기에 유일하게 눈물을 흘리게 만들었던 영화. 특히 음악은 최고다.</td>\n",
       "      <td>1</td>\n",
       "      <td>[나, 의, 질, 풍, 노도, 시기, 에, 유일, 하, 게, 눈물, 을, 흘리, 게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>다시 노래가 들려오는군..</td>\n",
       "      <td>1</td>\n",
       "      <td>[다시, 노래, 가, 들려오, 는군, ., .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review  y_test  \\\n",
       "368                     세월이 흘러도 잊혀지지 않는 생생한 OST의 전율       0   \n",
       "397                                 언제든 다시 봐도 명작.,.       1   \n",
       "1502                                             최고       1   \n",
       "1441  나의 질풍노도 시기에 유일하게 눈물을 흘리게 만들었던 영화. 특히 음악은 최고다.       1   \n",
       "1930                                 다시 노래가 들려오는군..       1   \n",
       "\n",
       "                                         X_test_tokkend  \n",
       "368   [세월, 이, 흐르, 어도, 잊히, 어, 지, 지, 않, 는, 생생, 하, ㄴ, O...  \n",
       "397                  [언제, 이, 든, 다시, 보, 아도, 명작, ., ,, .]  \n",
       "1502                                               [최고]  \n",
       "1441  [나, 의, 질, 풍, 노도, 시기, 에, 유일, 하, 게, 눈물, 을, 흘리, 게...  \n",
       "1930                         [다시, 노래, 가, 들려오, 는군, ., .]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer = Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=8,        # distance between the predicted word and context words\n",
    "    size=300,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=20,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=cores,   # multi cpu\n",
    "    hs = 1,          # hierarchical softmax / default 0\n",
    "    negative = 10,   # negative sampling / default 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-14 17:07:13,111 : INFO : collecting all words and their counts\n",
      "2019-01-14 17:07:13,113 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-1578b84a3f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_train_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_vectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[1;32m   1161\u001b[0m             \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m             \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m         )\n\u001b[1;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, corpus_file, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggedLineDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, documents, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0mdocument_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m                 \u001b[0m_note_doctag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['X_test_tokkend'] = df_test['review'].apply(lambda x :  tokenizer_komoran(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_train_docs = [TaggedDocument(d, c) for d, c in df[['tokens', 'emo']].values]\n",
    "tagged_test_docs = [TaggedDocument(d, c) for d, c in df_test[['X_test_tokkend', 'y_test']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040 3465\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_test_docs), len(tagged_train_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout\n",
    "from tensorflow.contrib.framework import arg_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "keep_prob = 0.7\n",
    "\n",
    "# Input Layer\n",
    "X = tf.placeholder(tf.float32, [None, 300])\n",
    "Y = tf.placeholder(tf.float32, [None, 3])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')\n",
    "\n",
    "# Layer output size\n",
    "hidden_output_size = 300\n",
    "final_ouput_size = 3\n",
    "\n",
    "# Xavier_Initializer\n",
    "xavier_init = tf.contrib.layers.xavier_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ouput_size = 3\n",
    "bn_params = {\n",
    "    'is_training': train_mode,\n",
    "    'decay':0.9,\n",
    "    'updates_collections':None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with arg_scope(\n",
    "    [fully_connected],\n",
    "    activation_fn=tf.nn.relu,\n",
    "    weights_initializer = xavier_init,\n",
    "    biases_initializer=None,\n",
    "    normalizer_fn=batch_norm,\n",
    "    normalizer_params=bn_params):\n",
    "\n",
    "    h1 = fully_connected(X, hidden_output_size, scope='h1')\n",
    "    dropout1 = dropout(h1, keep_prob, is_training=train_mode)\n",
    "\n",
    "    h2 = fully_connected(dropout1, hidden_output_size, scope='h2')\n",
    "    dropout2 = dropout(h2, keep_prob, is_training=train_mode)\n",
    "\n",
    "    h3 = fully_connected(dropout2, hidden_output_size, scope='h3')\n",
    "    dropout3 = dropout(h3, keep_prob, is_training=train_mode)\n",
    "\n",
    "    h4 = fully_connected(dropout3, hidden_output_size, scope='h4')\n",
    "    dropout4 = dropout(h4, keep_prob, is_training=train_mode)\n",
    "\n",
    "    hypothesis = fully_connected(dropout4, final_ouput_size, activation_fn=None, scope='hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-14 16:52:34,533 : WARNING : From <ipython-input-45-4ecdc95e0a10>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define Cost/Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.asarray([0 if c == 'NEG' else 1 if c == 'NEU' else 2 for c in y_train], dtype=int)\n",
    "y_test_np = np.asarray([0 if c == 'NEG' else 1 if c == 'NEU' else 2 for c in y_test], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = np.eye(3)[y_train_np.reshape(-1)]\n",
    "y_test_np = np.eye(3)[y_test_np.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "X_test_np = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['아직 안보신분 계시다면 추천해드리고 싶은 영화..',\n",
       "       '지금 써 내려가고 있는 젊은날의 초상화가 나에게도 영화처럼 깊은 감동이되기를.', '인생은 생각할수록 아름답다.',\n",
       "       ..., '늙어서 흰머리 파뿌리될때까지 내인생 최고의영화라고자부할수있는영화..감동쓰나미',\n",
       "       '어린시절 고딩때 봤던 때랑 또 결혼하고 나서 봤을때의 느낌은 확실히 다르네요. 뭔가 알프레도를 더 이해하게되고.. 토토와 알프레도의 우정이 정말 아름다운것이었음을, 토토의 첫사랑이 참 풋풋했음을 느낍니다~~그리고 언제들어도 사랑스러운 최고의 영화음악!',\n",
       "       '이런영화 또 나올려나.'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '아직 안보신분 계시다면 추천해드리고 싶은 영화..'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d213c7e95f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfeed_dict_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: {:4d} cost={:.9f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '아직 안보신분 계시다면 추천해드리고 싶은 영화..'"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(len(X_train_np)/batch_size)\n",
    "\n",
    "    for i in range(0, len(X_train_np), batch_size):\n",
    "        batch_xs = X_train_np[i:i+batch_size]\n",
    "        batch_ys = y_train_np[i:i+batch_size]\n",
    "\n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode:True }\n",
    "        feed_dict_cost = {X: batch_xs, Y: batch_ys, train_mode:False}\n",
    "\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict_train)\n",
    "        avg_cost += c / total_batch\n",
    "    print(\"Epoch: {:4d} cost={:.9f}\".format(epoch+1, avg_cost))\n",
    "\n",
    "print(\"Learning Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['아직 안보신분 계시다면 추천해드리고 싶은 영화..',\n",
       "       '지금 써 내려가고 있는 젊은날의 초상화가 나에게도 영화처럼 깊은 감동이되기를.', '인생은 생각할수록 아름답다.',\n",
       "       ..., '늙어서 흰머리 파뿌리될때까지 내인생 최고의영화라고자부할수있는영화..감동쓰나미',\n",
       "       '어린시절 고딩때 봤던 때랑 또 결혼하고 나서 봤을때의 느낌은 확실히 다르네요. 뭔가 알프레도를 더 이해하게되고.. 토토와 알프레도의 우정이 정말 아름다운것이었음을, 토토의 첫사랑이 참 풋풋했음을 느낍니다~~그리고 언제들어도 사랑스러운 최고의 영화음악!',\n",
       "       '이런영화 또 나올려나.'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95384616\n"
     ]
    }
   ],
   "source": [
    "# Test Model and Check Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict= {X:X_test_np, Y:y_test_np, train_mode:False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95384616"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(accuracy, feed_dict= {X:X_test_np, Y:y_test_np, train_mode:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, './model.pd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
